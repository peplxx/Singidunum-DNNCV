{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6f10bf",
   "metadata": {},
   "source": [
    "## CIFAR10 Solution\n",
    "\n",
    "![img](https://docs.pytorch.org/tutorials/_images/cifar10.png)\n",
    "> The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "Dataset [link](http://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "--- \n",
    "\n",
    "The CIFAR-10 dataset is solved using three different PyTorch approaches (barebone, Module API, and Sequential API) with convolutional neural networks for image classification across 10 object categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8cc615",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91dfc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589fb0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch.device: mps\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "USE_MPS = True\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif USE_MPS and torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using torch.device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d631a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 49_000\n",
    "NUM_VAL = 1_000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2175b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_t = (0.4816, 0.4646, 0.4168)\n",
    "std_t =  (0.2480, 0.2408, 0.2481)\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean_t, std_t)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "099ed1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = T.ToTensor()\n",
    "data_dir = \"./data\"\n",
    "\n",
    "train_set = datasets.CIFAR10(\n",
    "    root=data_dir, train=True, download=True, transform=transform\n",
    ")\n",
    "val_set = datasets.CIFAR10(\n",
    "    root=data_dir, train=True, download=True, transform=transform\n",
    ")\n",
    "test_set = datasets.CIFAR10(\n",
    "    root=data_dir, train=False, download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5734d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "Mean value: tensor([0.4816, 0.4646, 0.4168])\n",
      "Std value: tensor([0.2480, 0.2408, 0.2481])\n"
     ]
    }
   ],
   "source": [
    "##  Normalized Transformer + calculate mean, stg\n",
    "\n",
    "# loader_whole_train = DataLoader(train_set, batch_size=batch_size)\n",
    "\n",
    "# imgs, _ = next(iter(loader_whole_train)) #shape(N, 3, H, W)\n",
    "# print(imgs.shape)\n",
    "\n",
    "# mean = imgs.mean(dim=[0,2,3])\n",
    "\n",
    "# std = imgs.std(dim=[0,2,3])\n",
    "# print(f\"Mean value: {mean}\")\n",
    "# print(f\"Std value: {std}\")\n",
    "\n",
    "## Manually insert vallues and can be reused in previous step\n",
    "\n",
    "# transform = T.Compose([\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize(0.4816, 0.4646, 0.4168), (0.2480, 0.2408, 0.2481))\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b9b9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "__USE_PIN_MEMORY = USE_GPU * (not USE_MPS)\n",
    "loader_train = DataLoader(\n",
    "    train_set, \n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(range(NUM_TRAIN)),\n",
    "    num_workers=2,\n",
    "    pin_memory=__USE_PIN_MEMORY,\n",
    ")\n",
    "loader_val = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(range(NUM_TRAIN, NUM_TRAIN + NUM_VAL)),\n",
    "    num_workers=2,\n",
    "    pin_memory=__USE_PIN_MEMORY,\n",
    ")\n",
    "loader_test = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2,\n",
    "    pin_memory=__USE_PIN_MEMORY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d35b7",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a7e2b3",
   "metadata": {},
   "source": [
    "#### Explore dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a751f08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 50000\n",
      "Validation set size: 50000\n",
      "Test set size: 10000\n",
      "\n",
      "Num of classes: 10\n",
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "airplane   - 5000 images\n",
      "automobile - 5000 images\n",
      "bird       - 5000 images\n",
      "cat        - 5000 images\n",
      "deer       - 5000 images\n",
      "dog        - 5000 images\n",
      "frog       - 5000 images\n",
      "horse      - 5000 images\n",
      "ship       - 5000 images\n",
      "truck      - 5000 images\n",
      "\n",
      "Batch shape: torch.Size([128, 3, 32, 32])\n",
      "One image shape: torch.Size([3, 32, 32])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "print(f\"Train set size: {len(train_set)}\")\n",
    "print(f\"Validation set size: {len(val_set)}\")\n",
    "print(f\"Test set size: {len(test_set)}\")\n",
    "print()\n",
    "\n",
    "classes = train_set.classes\n",
    "print(f\"Num of classes: {len(classes)}\")\n",
    "print(f\"Classes: {classes}\")\n",
    "labels_counter = Counter([i[1] for i in train_set])\n",
    "for i, label in enumerate(classes):\n",
    "    print(f\"{label:10} - {labels_counter[i]} images\")\n",
    "print()\n",
    "\n",
    "xb, yb = next(iter(loader_train))\n",
    "print(f\"Batch shape: {xb.shape}\")\n",
    "print(f\"One image shape: {xb[0].shape}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f2a716",
   "metadata": {},
   "source": [
    "#### Show first class images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee52c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 6, 25, 0, 22, 12, 4, 13, 1, 11]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean = torch.tensor(mean_t).view(3,1,1)\n",
    "std = torch.tensor(std_t).view(3,1,1)\n",
    "\n",
    "examples = [None] * len(classes)\n",
    "for i, (x,y) in enumerate(test_set):\n",
    "    if (examples[y] is None):\n",
    "        examples[y] = i\n",
    "    if all((e is not None for e in examples)):\n",
    "        break\n",
    "print(examples)\n",
    "\n",
    "fig, axs = plt.subplots(*(2, 5), figsize=(10,6))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    index = examples[i]\n",
    "    x, y = test_set[index]\n",
    "    x_disp = (x * std + mean).clamp(0, 1)\n",
    "    ax.imshow(x_disp.permute(1,2,0).cpu().numpy())\n",
    "    ax.set_title(classes[i])\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a570b47",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f77142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict(train_x, train_y, xq, k=5):\n",
    "    a2 = (xq**2).sum(1, keepdim=True)\n",
    "    b2 = (train_x**2).sum(1, keepdim=True).T\n",
    "    d2 = a2 + b2 - 2 * xq@train_x.T\n",
    "    \n",
    "    idx = torch.topk(-d2, k=k, dim=1).indices\n",
    "    neigh = train_y[idx]\n",
    "    \n",
    "    preds = torch.mode(neigh, dim=1).values\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "117498c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_matrix(dloader, limit=1000):\n",
    "    xs, ys = [], []\n",
    "    for x, y in dloader:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        xs.append(x.cpu())\n",
    "        ys.append(y.cpu())\n",
    "        if sum([len(a) for a in xs]) >= limit: break\n",
    "\n",
    "    X = torch.cat(xs, 0)[:limit].float()\n",
    "    Y = torch.cat(ys, 0)[:limit].float()\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cec9b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Ytr = build_matrix(loader_test, limit=2000)\n",
    "Xva, Yva = build_matrix(loader_val, limit=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21bcff30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.00\n"
     ]
    }
   ],
   "source": [
    "preds = knn_predict(Xtr, Ytr, Xva, k=5)\n",
    "\n",
    "acc = (preds==Yva).float().mean().item()\n",
    "\n",
    "print(f\"{acc*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e7a58",
   "metadata": {},
   "source": [
    "## Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef9f6957",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_np = Xtr.cpu().numpy() if hasattr(Xtr, \"cpu\") else Xtr\n",
    "Ytr_np = Ytr.cpu().numpy() if hasattr(Ytr, \"cpu\") else Ytr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27c754e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xd shape: (256, 3072)\n",
      "Yd shape: (256,)\n"
     ]
    }
   ],
   "source": [
    "Ndemo = 256\n",
    "Xd = Xtr_np[:Ndemo].astype(np.float32, copy=False)\n",
    "Yd = Ytr_np[:Ndemo].astype(np.int64, copy=False)\n",
    "\n",
    "print(f\"Xd shape: {Xd.shape}\")\n",
    "print(f\"Yd shape: {Yd.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b913a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Xd.shape[1]\n",
    "C = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd8b1776",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "w = 0.001 * rng.randn(D, C).astype(np.float32)\n",
    "reg = 1e-4\n",
    "\n",
    "# forward\n",
    "scores = Xd.dot(w)\n",
    "\n",
    "scores -= scores.max(axis=1, keepdims=True)\n",
    "exp = np.exp(scores)\n",
    "probs = exp / np.sum(exp, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "702e21f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax loss: 2.3136\n"
     ]
    }
   ],
   "source": [
    "loss_data = -np.log(probs[np.arange(Ndemo), Yd]).mean()\n",
    "loss_reg = 0.5 * reg * np.sum(w*w)\n",
    "loss = loss_data + loss_reg\n",
    "\n",
    "print(f\"Softmax loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3b8d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "dscores = probs\n",
    "dscores [np. arange (Ndemo), Yd] - 1\n",
    "dscores /= Ndemo\n",
    "dW = Xd.T.dot (dscores) + reg*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53e9f8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W shape:, (3072, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"W shape:,\", w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b707ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-0\n",
    "w -= lr*dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c58724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after one update: 13.28%\n"
     ]
    }
   ],
   "source": [
    "scores = Xd.dot(w) # logits for all samples\n",
    "preds = scores.argmax(axis=1) #predicted class per sample\n",
    "acc = (preds == Yd).mean() # mean of correct predictions\n",
    "print(f\"Accuracy after one update: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d64a0f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for first sample:  6\n"
     ]
    }
   ],
   "source": [
    "x_new = Xd [0:1] # shape(1, D)\n",
    "logits = x_new.dot (w) # (1, C)\n",
    "pred = logits.argmax(axis=1) # scalar class id\n",
    "print(\"Predicted class for first sample: \", pred. item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b25080",
   "metadata": {},
   "source": [
    "#### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "183ac5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSoftMax(nn.Module):\n",
    "    def __init__(self, D, C):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = nn.Linear(D,C)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "def train_epoch(model, loader, opt, loss_fn):\n",
    "    model.train()\n",
    "    losses, correct, total = [], 0, 0\n",
    "\n",
    "    for x,y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        scores = model(x)\n",
    "        loss = loss_fn(scores, y)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses += [loss.item()]\n",
    "        pred = scores.argmax(1)\n",
    "        correct += (pred==y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return np.mean(losses), correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98785098",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    losses, correct, total = [], 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        scores = model(x)\n",
    "        loss = loss_fn(scores, y)\n",
    "\n",
    "        losses += [loss.item()]\n",
    "        pred = scores.argmax(1)\n",
    "        correct += (pred==y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return np.mean(losses), correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b2b6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSoftMax(D, C).to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8beca912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 1/3, train (loss, acc): 18.691108688673214, 0.29336734693877553 | validation (loss, acc): 17.03781545162201, 0.282\n",
      "ep: 2/3, train (loss, acc): 18.984042605905557, 0.29436734693877553 | validation (loss, acc): 16.928399085998535, 0.265\n",
      "ep: 3/3, train (loss, acc): 17.736948222466612, 0.29889795918367346 | validation (loss, acc): 24.57183527946472, 0.29\n"
     ]
    }
   ],
   "source": [
    "for ep in range(3):\n",
    "    tr_loss, tr_acc = train_epoch(model,loader_train, opt, loss_fn)\n",
    "    va_loss, va_acc = eval_model(model, loader_val, loss_fn)\n",
    "    print(f\"ep: {ep+1}/3, train (loss, acc): {tr_loss}, {tr_acc} | validation (loss, acc): {va_loss}, {va_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb94929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test (loss, accuracy): 24.89730460734307, 28.41%\n"
     ]
    }
   ],
   "source": [
    "tst_loss, tst_acc = eval_model(model, loader_test, loss_fn)\n",
    "print(f\"Final test (loss, accuracy): {tst_loss}, {tst_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21531f10",
   "metadata": {},
   "source": [
    "## Barebone PyTorch Approach (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8eec3d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1],\n",
      "          [ 2,  3],\n",
      "          [ 4,  5]]],\n",
      "\n",
      "\n",
      "        [[[ 6,  7],\n",
      "          [ 8,  9],\n",
      "          [10, 11]]]])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0]  # [N, C, H, W] -> [N, C * H * W]\n",
    "    return x.view(N, -1)\n",
    "\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print(x)\n",
    "    print(flatten(x))\n",
    "\n",
    "\n",
    "test_flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "348a3f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_convnet(x, params):\n",
    "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
    "    scores = None\n",
    "\n",
    "    # Forward pass for 3-layer convnet\n",
    "    x = F.relu(F.conv2d(x, conv_w1, conv_b1, padding=2))\n",
    "    x = F.relu(F.conv2d(x, conv_w2, conv_b2, padding=3))\n",
    "\n",
    "    scores = flatten(x).mm(fc_w) + fc_b\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1607de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "def three_layer_convnet_test():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)\n",
    "\n",
    "    # out_channel, in_channel, kernel_H, kernel_W\n",
    "    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)\n",
    "    conv_b1 = torch.zeros((6,), dtype=dtype)  # out_channel\\\n",
    "\n",
    "    conv_w2 = torch.zeros((9, 6, 7, 7), dtype=dtype)\n",
    "    conv_b2 = torch.zeros((9,), dtype=dtype)\n",
    "\n",
    "    fc_w = torch.zeros((9 * 32 * 32, 10))\n",
    "    fc_b = torch.zeros((10))\n",
    "\n",
    "    scores = three_layer_convnet(x, (conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b))\n",
    "    print(scores.size())\n",
    "\n",
    "\n",
    "three_layer_convnet_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce12963b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0862,  1.3392, -0.7153,  0.8380, -0.6382],\n",
       "        [ 0.2291, -1.1612, -1.4404,  1.2302,  0.0703],\n",
       "        [-2.7175,  0.2669, -0.2979,  1.9289,  1.5645]], device='mps:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_weight(shape):\n",
    "    if len(shape) == 2:\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:])  # Conv weight [out_chan, in_chan, kH, kW]\n",
    "\n",
    "    w = torch.randn(shape, device=device, dtype=dtype)\n",
    "    w = w * np.sqrt(2.0 / fan_in)\n",
    "    w.requires_grad_(True)\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def zero_weight(shape):\n",
    "    torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "\n",
    "random_weight((3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77731984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model_fn, params):\n",
    "    split = \"val\" if loader.dataset.train else \"test\"\n",
    "    print(f\"Checking accuracy on the, {split} set\")\n",
    "\n",
    "    num_correct, num_samples = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.int64)\n",
    "\n",
    "            scores = model_fn(x, params)\n",
    "            _, preds = scores.max(1)\n",
    "\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print(\"Got %d / %d correct (%.2f%%)\" % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1634a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model_fn, params, learing_rate, *, epochs=2, print_every=10):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.int64)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model_fn(x, params)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for w in params:\n",
    "                    w -= learing_rate * w.grad\n",
    "                    w.grad.zero_()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print(f\"Ireration: {t} loss: {loss.item()}\")\n",
    "                check_accuracy(loader_val, model_fn, params)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8cbe9106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Ireration: 0 loss: 4.620083808898926\n",
      "Checking accuracy on the, val set\n",
      "Got 81 / 1000 correct (8.10%)\n",
      "\n",
      "Ireration: 10 loss: 2.3530941009521484\n",
      "Checking accuracy on the, val set\n",
      "Got 132 / 1000 correct (13.20%)\n",
      "\n",
      "Ireration: 20 loss: 2.309741497039795\n",
      "Checking accuracy on the, val set\n",
      "Got 116 / 1000 correct (11.60%)\n",
      "\n",
      "Ireration: 30 loss: 2.2887091636657715\n",
      "Checking accuracy on the, val set\n",
      "Got 180 / 1000 correct (18.00%)\n",
      "\n",
      "Ireration: 40 loss: 2.272648334503174\n",
      "Checking accuracy on the, val set\n",
      "Got 182 / 1000 correct (18.20%)\n",
      "\n",
      "Ireration: 50 loss: 2.187894821166992\n",
      "Checking accuracy on the, val set\n",
      "Got 177 / 1000 correct (17.70%)\n",
      "\n",
      "Ireration: 60 loss: 2.2128167152404785\n",
      "Checking accuracy on the, val set\n",
      "Got 203 / 1000 correct (20.30%)\n",
      "\n",
      "Ireration: 70 loss: 2.1692466735839844\n",
      "Checking accuracy on the, val set\n",
      "Got 229 / 1000 correct (22.90%)\n",
      "\n",
      "Ireration: 80 loss: 2.1284427642822266\n",
      "Checking accuracy on the, val set\n",
      "Got 239 / 1000 correct (23.90%)\n",
      "\n",
      "Ireration: 90 loss: 2.059196710586548\n",
      "Checking accuracy on the, val set\n",
      "Got 236 / 1000 correct (23.60%)\n",
      "\n",
      "Ireration: 100 loss: 2.1805477142333984\n",
      "Checking accuracy on the, val set\n",
      "Got 228 / 1000 correct (22.80%)\n",
      "\n",
      "Ireration: 110 loss: 2.2158291339874268\n",
      "Checking accuracy on the, val set\n",
      "Got 211 / 1000 correct (21.10%)\n",
      "\n",
      "Ireration: 120 loss: 2.160282611846924\n",
      "Checking accuracy on the, val set\n",
      "Got 246 / 1000 correct (24.60%)\n",
      "\n",
      "Ireration: 130 loss: 2.2160284519195557\n",
      "Checking accuracy on the, val set\n",
      "Got 216 / 1000 correct (21.60%)\n",
      "\n",
      "Ireration: 140 loss: 2.062885046005249\n",
      "Checking accuracy on the, val set\n",
      "Got 225 / 1000 correct (22.50%)\n",
      "\n",
      "Ireration: 150 loss: 2.079399585723877\n",
      "Checking accuracy on the, val set\n",
      "Got 257 / 1000 correct (25.70%)\n",
      "\n",
      "Ireration: 160 loss: 2.13383412361145\n",
      "Checking accuracy on the, val set\n",
      "Got 235 / 1000 correct (23.50%)\n",
      "\n",
      "Ireration: 170 loss: 2.0541062355041504\n",
      "Checking accuracy on the, val set\n",
      "Got 254 / 1000 correct (25.40%)\n",
      "\n",
      "Ireration: 180 loss: 1.8914830684661865\n",
      "Checking accuracy on the, val set\n",
      "Got 257 / 1000 correct (25.70%)\n",
      "\n",
      "Ireration: 190 loss: 2.0353753566741943\n",
      "Checking accuracy on the, val set\n",
      "Got 284 / 1000 correct (28.40%)\n",
      "\n",
      "Ireration: 200 loss: 1.8545960187911987\n",
      "Checking accuracy on the, val set\n",
      "Got 266 / 1000 correct (26.60%)\n",
      "\n",
      "Ireration: 210 loss: 2.1095142364501953\n",
      "Checking accuracy on the, val set\n",
      "Got 262 / 1000 correct (26.20%)\n",
      "\n",
      "Ireration: 220 loss: 2.1166553497314453\n",
      "Checking accuracy on the, val set\n",
      "Got 248 / 1000 correct (24.80%)\n",
      "\n",
      "Ireration: 230 loss: 2.06997013092041\n",
      "Checking accuracy on the, val set\n",
      "Got 265 / 1000 correct (26.50%)\n",
      "\n",
      "Ireration: 240 loss: 1.9976495504379272\n",
      "Checking accuracy on the, val set\n",
      "Got 288 / 1000 correct (28.80%)\n",
      "\n",
      "Ireration: 250 loss: 2.0178868770599365\n",
      "Checking accuracy on the, val set\n",
      "Got 279 / 1000 correct (27.90%)\n",
      "\n",
      "Ireration: 260 loss: 1.9749889373779297\n",
      "Checking accuracy on the, val set\n",
      "Got 309 / 1000 correct (30.90%)\n",
      "\n",
      "Ireration: 270 loss: 1.834791898727417\n",
      "Checking accuracy on the, val set\n",
      "Got 299 / 1000 correct (29.90%)\n",
      "\n",
      "Ireration: 280 loss: 2.0412020683288574\n",
      "Checking accuracy on the, val set\n",
      "Got 278 / 1000 correct (27.80%)\n",
      "\n",
      "Ireration: 290 loss: 2.0400538444519043\n",
      "Checking accuracy on the, val set\n",
      "Got 324 / 1000 correct (32.40%)\n",
      "\n",
      "Ireration: 300 loss: 2.0697860717773438\n",
      "Checking accuracy on the, val set\n",
      "Got 314 / 1000 correct (31.40%)\n",
      "\n",
      "Ireration: 310 loss: 1.8617106676101685\n",
      "Checking accuracy on the, val set\n",
      "Got 303 / 1000 correct (30.30%)\n",
      "\n",
      "Ireration: 320 loss: 1.9257193803787231\n",
      "Checking accuracy on the, val set\n",
      "Got 313 / 1000 correct (31.30%)\n",
      "\n",
      "Ireration: 330 loss: 2.085949659347534\n",
      "Checking accuracy on the, val set\n",
      "Got 337 / 1000 correct (33.70%)\n",
      "\n",
      "Ireration: 340 loss: 1.9847527742385864\n",
      "Checking accuracy on the, val set\n",
      "Got 288 / 1000 correct (28.80%)\n",
      "\n",
      "Ireration: 350 loss: 1.9060612916946411\n",
      "Checking accuracy on the, val set\n",
      "Got 309 / 1000 correct (30.90%)\n",
      "\n",
      "Ireration: 360 loss: 1.9131052494049072\n",
      "Checking accuracy on the, val set\n",
      "Got 298 / 1000 correct (29.80%)\n",
      "\n",
      "Ireration: 370 loss: 1.9904130697250366\n",
      "Checking accuracy on the, val set\n",
      "Got 329 / 1000 correct (32.90%)\n",
      "\n",
      "Ireration: 380 loss: 1.8756787776947021\n",
      "Checking accuracy on the, val set\n",
      "Got 319 / 1000 correct (31.90%)\n",
      "\n",
      "Ireration: 390 loss: 1.8569823503494263\n",
      "Checking accuracy on the, val set\n",
      "Got 331 / 1000 correct (33.10%)\n",
      "\n",
      "Ireration: 400 loss: 1.8925836086273193\n",
      "Checking accuracy on the, val set\n",
      "Got 328 / 1000 correct (32.80%)\n",
      "\n",
      "Ireration: 410 loss: 1.9010436534881592\n",
      "Checking accuracy on the, val set\n",
      "Got 277 / 1000 correct (27.70%)\n",
      "\n",
      "Ireration: 420 loss: 1.83673095703125\n",
      "Checking accuracy on the, val set\n",
      "Got 342 / 1000 correct (34.20%)\n",
      "\n",
      "Ireration: 430 loss: 1.8575029373168945\n",
      "Checking accuracy on the, val set\n",
      "Got 344 / 1000 correct (34.40%)\n",
      "\n",
      "Ireration: 440 loss: 1.938528060913086\n",
      "Checking accuracy on the, val set\n",
      "Got 335 / 1000 correct (33.50%)\n",
      "\n",
      "Ireration: 450 loss: 1.7739861011505127\n",
      "Checking accuracy on the, val set\n",
      "Got 298 / 1000 correct (29.80%)\n",
      "\n",
      "Ireration: 460 loss: 2.007575511932373\n",
      "Checking accuracy on the, val set\n",
      "Got 335 / 1000 correct (33.50%)\n",
      "\n",
      "Ireration: 470 loss: 1.938234806060791\n",
      "Checking accuracy on the, val set\n",
      "Got 337 / 1000 correct (33.70%)\n",
      "\n",
      "Ireration: 480 loss: 1.8372199535369873\n",
      "Checking accuracy on the, val set\n",
      "Got 344 / 1000 correct (34.40%)\n",
      "\n",
      "Ireration: 490 loss: 1.8781533241271973\n",
      "Checking accuracy on the, val set\n",
      "Got 329 / 1000 correct (32.90%)\n",
      "\n",
      "Ireration: 500 loss: 1.9811458587646484\n",
      "Checking accuracy on the, val set\n",
      "Got 320 / 1000 correct (32.00%)\n",
      "\n",
      "Ireration: 510 loss: 1.996866226196289\n",
      "Checking accuracy on the, val set\n",
      "Got 341 / 1000 correct (34.10%)\n",
      "\n",
      "Ireration: 520 loss: 1.8101115226745605\n",
      "Checking accuracy on the, val set\n",
      "Got 355 / 1000 correct (35.50%)\n",
      "\n",
      "Ireration: 530 loss: 1.7722318172454834\n",
      "Checking accuracy on the, val set\n",
      "Got 307 / 1000 correct (30.70%)\n",
      "\n",
      "Ireration: 540 loss: 1.8869414329528809\n",
      "Checking accuracy on the, val set\n",
      "Got 358 / 1000 correct (35.80%)\n",
      "\n",
      "Ireration: 550 loss: 1.8685612678527832\n",
      "Checking accuracy on the, val set\n",
      "Got 287 / 1000 correct (28.70%)\n",
      "\n",
      "Ireration: 560 loss: 1.9656367301940918\n",
      "Checking accuracy on the, val set\n",
      "Got 327 / 1000 correct (32.70%)\n",
      "\n",
      "Ireration: 570 loss: 1.9131479263305664\n",
      "Checking accuracy on the, val set\n",
      "Got 326 / 1000 correct (32.60%)\n",
      "\n",
      "Ireration: 580 loss: 1.9239150285720825\n",
      "Checking accuracy on the, val set\n",
      "Got 338 / 1000 correct (33.80%)\n",
      "\n",
      "Ireration: 590 loss: 1.959303855895996\n",
      "Checking accuracy on the, val set\n",
      "Got 364 / 1000 correct (36.40%)\n",
      "\n",
      "Ireration: 600 loss: 1.9278998374938965\n",
      "Checking accuracy on the, val set\n",
      "Got 370 / 1000 correct (37.00%)\n",
      "\n",
      "Ireration: 610 loss: 1.7593188285827637\n",
      "Checking accuracy on the, val set\n",
      "Got 345 / 1000 correct (34.50%)\n",
      "\n",
      "Ireration: 620 loss: 1.9103996753692627\n",
      "Checking accuracy on the, val set\n",
      "Got 359 / 1000 correct (35.90%)\n",
      "\n",
      "Ireration: 630 loss: 1.9871740341186523\n",
      "Checking accuracy on the, val set\n",
      "Got 346 / 1000 correct (34.60%)\n",
      "\n",
      "Ireration: 640 loss: 1.8712042570114136\n",
      "Checking accuracy on the, val set\n",
      "Got 342 / 1000 correct (34.20%)\n",
      "\n",
      "Ireration: 650 loss: 1.7543214559555054\n",
      "Checking accuracy on the, val set\n",
      "Got 366 / 1000 correct (36.60%)\n",
      "\n",
      "Ireration: 660 loss: 1.693603754043579\n",
      "Checking accuracy on the, val set\n",
      "Got 357 / 1000 correct (35.70%)\n",
      "\n",
      "Ireration: 670 loss: 1.8994762897491455\n",
      "Checking accuracy on the, val set\n",
      "Got 361 / 1000 correct (36.10%)\n",
      "\n",
      "Ireration: 680 loss: 1.7969179153442383\n",
      "Checking accuracy on the, val set\n",
      "Got 384 / 1000 correct (38.40%)\n",
      "\n",
      "Ireration: 690 loss: 1.890498399734497\n",
      "Checking accuracy on the, val set\n",
      "Got 350 / 1000 correct (35.00%)\n",
      "\n",
      "Ireration: 700 loss: 1.9830784797668457\n",
      "Checking accuracy on the, val set\n",
      "Got 318 / 1000 correct (31.80%)\n",
      "\n",
      "Ireration: 710 loss: 1.942448377609253\n",
      "Checking accuracy on the, val set\n",
      "Got 340 / 1000 correct (34.00%)\n",
      "\n",
      "Ireration: 720 loss: 1.7474887371063232\n",
      "Checking accuracy on the, val set\n",
      "Got 367 / 1000 correct (36.70%)\n",
      "\n",
      "Ireration: 730 loss: 1.7610387802124023\n",
      "Checking accuracy on the, val set\n",
      "Got 376 / 1000 correct (37.60%)\n",
      "\n",
      "Ireration: 740 loss: 2.0961203575134277\n",
      "Checking accuracy on the, val set\n",
      "Got 296 / 1000 correct (29.60%)\n",
      "\n",
      "Ireration: 750 loss: 1.8844318389892578\n",
      "Checking accuracy on the, val set\n",
      "Got 339 / 1000 correct (33.90%)\n",
      "\n",
      "Ireration: 760 loss: 1.8735395669937134\n",
      "Checking accuracy on the, val set\n",
      "Got 365 / 1000 correct (36.50%)\n",
      "\n",
      "Epoch 2/2\n",
      "Ireration: 0 loss: 1.6961432695388794\n",
      "Checking accuracy on the, val set\n",
      "Got 341 / 1000 correct (34.10%)\n",
      "\n",
      "Ireration: 10 loss: 1.5827903747558594\n",
      "Checking accuracy on the, val set\n",
      "Got 350 / 1000 correct (35.00%)\n",
      "\n",
      "Ireration: 20 loss: 1.7891591787338257\n",
      "Checking accuracy on the, val set\n",
      "Got 350 / 1000 correct (35.00%)\n",
      "\n",
      "Ireration: 30 loss: 1.9140703678131104\n",
      "Checking accuracy on the, val set\n",
      "Got 344 / 1000 correct (34.40%)\n",
      "\n",
      "Ireration: 40 loss: 2.0468573570251465\n",
      "Checking accuracy on the, val set\n",
      "Got 366 / 1000 correct (36.60%)\n",
      "\n",
      "Ireration: 50 loss: 1.877174973487854\n",
      "Checking accuracy on the, val set\n",
      "Got 370 / 1000 correct (37.00%)\n",
      "\n",
      "Ireration: 60 loss: 1.8971294164657593\n",
      "Checking accuracy on the, val set\n",
      "Got 338 / 1000 correct (33.80%)\n",
      "\n",
      "Ireration: 70 loss: 1.8297704458236694\n",
      "Checking accuracy on the, val set\n",
      "Got 390 / 1000 correct (39.00%)\n",
      "\n",
      "Ireration: 80 loss: 1.8683805465698242\n",
      "Checking accuracy on the, val set\n",
      "Got 398 / 1000 correct (39.80%)\n",
      "\n",
      "Ireration: 90 loss: 1.881223440170288\n",
      "Checking accuracy on the, val set\n",
      "Got 388 / 1000 correct (38.80%)\n",
      "\n",
      "Ireration: 100 loss: 1.9576643705368042\n",
      "Checking accuracy on the, val set\n",
      "Got 325 / 1000 correct (32.50%)\n",
      "\n",
      "Ireration: 110 loss: 1.7857247591018677\n",
      "Checking accuracy on the, val set\n",
      "Got 389 / 1000 correct (38.90%)\n",
      "\n",
      "Ireration: 120 loss: 1.849318265914917\n",
      "Checking accuracy on the, val set\n",
      "Got 388 / 1000 correct (38.80%)\n",
      "\n",
      "Ireration: 130 loss: 1.7573888301849365\n",
      "Checking accuracy on the, val set\n",
      "Got 375 / 1000 correct (37.50%)\n",
      "\n",
      "Ireration: 140 loss: 1.9141532182693481\n",
      "Checking accuracy on the, val set\n",
      "Got 374 / 1000 correct (37.40%)\n",
      "\n",
      "Ireration: 150 loss: 1.8819499015808105\n",
      "Checking accuracy on the, val set\n",
      "Got 408 / 1000 correct (40.80%)\n",
      "\n",
      "Ireration: 160 loss: 1.8297775983810425\n",
      "Checking accuracy on the, val set\n",
      "Got 370 / 1000 correct (37.00%)\n",
      "\n",
      "Ireration: 170 loss: 1.7820268869400024\n",
      "Checking accuracy on the, val set\n",
      "Got 398 / 1000 correct (39.80%)\n",
      "\n",
      "Ireration: 180 loss: 1.794508695602417\n",
      "Checking accuracy on the, val set\n",
      "Got 401 / 1000 correct (40.10%)\n",
      "\n",
      "Ireration: 190 loss: 1.611525535583496\n",
      "Checking accuracy on the, val set\n",
      "Got 363 / 1000 correct (36.30%)\n",
      "\n",
      "Ireration: 200 loss: 1.897049903869629\n",
      "Checking accuracy on the, val set\n",
      "Got 365 / 1000 correct (36.50%)\n",
      "\n",
      "Ireration: 210 loss: 1.9200687408447266\n",
      "Checking accuracy on the, val set\n",
      "Got 406 / 1000 correct (40.60%)\n",
      "\n",
      "Ireration: 220 loss: 1.824820637702942\n",
      "Checking accuracy on the, val set\n",
      "Got 363 / 1000 correct (36.30%)\n",
      "\n",
      "Ireration: 230 loss: 1.7718744277954102\n",
      "Checking accuracy on the, val set\n",
      "Got 380 / 1000 correct (38.00%)\n",
      "\n",
      "Ireration: 240 loss: 1.537585973739624\n",
      "Checking accuracy on the, val set\n",
      "Got 401 / 1000 correct (40.10%)\n",
      "\n",
      "Ireration: 250 loss: 1.7989953756332397\n",
      "Checking accuracy on the, val set\n",
      "Got 394 / 1000 correct (39.40%)\n",
      "\n",
      "Ireration: 260 loss: 1.8595130443572998\n",
      "Checking accuracy on the, val set\n",
      "Got 389 / 1000 correct (38.90%)\n",
      "\n",
      "Ireration: 270 loss: 1.8458894491195679\n",
      "Checking accuracy on the, val set\n",
      "Got 382 / 1000 correct (38.20%)\n",
      "\n",
      "Ireration: 280 loss: 1.6843347549438477\n",
      "Checking accuracy on the, val set\n",
      "Got 399 / 1000 correct (39.90%)\n",
      "\n",
      "Ireration: 290 loss: 1.8660147190093994\n",
      "Checking accuracy on the, val set\n",
      "Got 390 / 1000 correct (39.00%)\n",
      "\n",
      "Ireration: 300 loss: 1.814766526222229\n",
      "Checking accuracy on the, val set\n",
      "Got 383 / 1000 correct (38.30%)\n",
      "\n",
      "Ireration: 310 loss: 1.785711646080017\n",
      "Checking accuracy on the, val set\n",
      "Got 406 / 1000 correct (40.60%)\n",
      "\n",
      "Ireration: 320 loss: 1.8524606227874756\n",
      "Checking accuracy on the, val set\n",
      "Got 403 / 1000 correct (40.30%)\n",
      "\n",
      "Ireration: 330 loss: 1.5753200054168701\n",
      "Checking accuracy on the, val set\n",
      "Got 379 / 1000 correct (37.90%)\n",
      "\n",
      "Ireration: 340 loss: 1.568721055984497\n",
      "Checking accuracy on the, val set\n",
      "Got 357 / 1000 correct (35.70%)\n",
      "\n",
      "Ireration: 350 loss: 1.7886061668395996\n",
      "Checking accuracy on the, val set\n",
      "Got 400 / 1000 correct (40.00%)\n",
      "\n",
      "Ireration: 360 loss: 1.6053155660629272\n",
      "Checking accuracy on the, val set\n",
      "Got 379 / 1000 correct (37.90%)\n",
      "\n",
      "Ireration: 370 loss: 1.7873249053955078\n",
      "Checking accuracy on the, val set\n",
      "Got 375 / 1000 correct (37.50%)\n",
      "\n",
      "Ireration: 380 loss: 1.7044917345046997\n",
      "Checking accuracy on the, val set\n",
      "Got 386 / 1000 correct (38.60%)\n",
      "\n",
      "Ireration: 390 loss: 1.6937211751937866\n",
      "Checking accuracy on the, val set\n",
      "Got 408 / 1000 correct (40.80%)\n",
      "\n",
      "Ireration: 400 loss: 1.636600136756897\n",
      "Checking accuracy on the, val set\n",
      "Got 371 / 1000 correct (37.10%)\n",
      "\n",
      "Ireration: 410 loss: 1.7063143253326416\n",
      "Checking accuracy on the, val set\n",
      "Got 375 / 1000 correct (37.50%)\n",
      "\n",
      "Ireration: 420 loss: 1.8075461387634277\n",
      "Checking accuracy on the, val set\n",
      "Got 404 / 1000 correct (40.40%)\n",
      "\n",
      "Ireration: 430 loss: 1.9999122619628906\n",
      "Checking accuracy on the, val set\n",
      "Got 416 / 1000 correct (41.60%)\n",
      "\n",
      "Ireration: 440 loss: 1.7177162170410156\n",
      "Checking accuracy on the, val set\n",
      "Got 382 / 1000 correct (38.20%)\n",
      "\n",
      "Ireration: 450 loss: 1.6896578073501587\n",
      "Checking accuracy on the, val set\n",
      "Got 388 / 1000 correct (38.80%)\n",
      "\n",
      "Ireration: 460 loss: 1.6409263610839844\n",
      "Checking accuracy on the, val set\n",
      "Got 412 / 1000 correct (41.20%)\n",
      "\n",
      "Ireration: 470 loss: 1.6564525365829468\n",
      "Checking accuracy on the, val set\n",
      "Got 400 / 1000 correct (40.00%)\n",
      "\n",
      "Ireration: 480 loss: 1.7461445331573486\n",
      "Checking accuracy on the, val set\n",
      "Got 398 / 1000 correct (39.80%)\n",
      "\n",
      "Ireration: 490 loss: 1.6767237186431885\n",
      "Checking accuracy on the, val set\n",
      "Got 422 / 1000 correct (42.20%)\n",
      "\n",
      "Ireration: 500 loss: 1.878523349761963\n",
      "Checking accuracy on the, val set\n",
      "Got 405 / 1000 correct (40.50%)\n",
      "\n",
      "Ireration: 510 loss: 1.6983736753463745\n",
      "Checking accuracy on the, val set\n",
      "Got 404 / 1000 correct (40.40%)\n",
      "\n",
      "Ireration: 520 loss: 1.8901572227478027\n",
      "Checking accuracy on the, val set\n",
      "Got 409 / 1000 correct (40.90%)\n",
      "\n",
      "Ireration: 530 loss: 1.660524606704712\n",
      "Checking accuracy on the, val set\n",
      "Got 417 / 1000 correct (41.70%)\n",
      "\n",
      "Ireration: 540 loss: 1.5869359970092773\n",
      "Checking accuracy on the, val set\n",
      "Got 399 / 1000 correct (39.90%)\n",
      "\n",
      "Ireration: 550 loss: 1.606871247291565\n",
      "Checking accuracy on the, val set\n",
      "Got 418 / 1000 correct (41.80%)\n",
      "\n",
      "Ireration: 560 loss: 1.6543697118759155\n",
      "Checking accuracy on the, val set\n",
      "Got 406 / 1000 correct (40.60%)\n",
      "\n",
      "Ireration: 570 loss: 1.8407728672027588\n",
      "Checking accuracy on the, val set\n",
      "Got 395 / 1000 correct (39.50%)\n",
      "\n",
      "Ireration: 580 loss: 1.6108057498931885\n",
      "Checking accuracy on the, val set\n",
      "Got 414 / 1000 correct (41.40%)\n",
      "\n",
      "Ireration: 590 loss: 1.6804002523422241\n",
      "Checking accuracy on the, val set\n",
      "Got 420 / 1000 correct (42.00%)\n",
      "\n",
      "Ireration: 600 loss: 1.7457201480865479\n",
      "Checking accuracy on the, val set\n",
      "Got 399 / 1000 correct (39.90%)\n",
      "\n",
      "Ireration: 610 loss: 1.6013096570968628\n",
      "Checking accuracy on the, val set\n",
      "Got 409 / 1000 correct (40.90%)\n",
      "\n",
      "Ireration: 620 loss: 1.6676973104476929\n",
      "Checking accuracy on the, val set\n",
      "Got 407 / 1000 correct (40.70%)\n",
      "\n",
      "Ireration: 630 loss: 1.5576286315917969\n",
      "Checking accuracy on the, val set\n",
      "Got 395 / 1000 correct (39.50%)\n",
      "\n",
      "Ireration: 640 loss: 1.815880537033081\n",
      "Checking accuracy on the, val set\n",
      "Got 369 / 1000 correct (36.90%)\n",
      "\n",
      "Ireration: 650 loss: 1.5269324779510498\n",
      "Checking accuracy on the, val set\n",
      "Got 388 / 1000 correct (38.80%)\n",
      "\n",
      "Ireration: 660 loss: 1.628269910812378\n",
      "Checking accuracy on the, val set\n",
      "Got 376 / 1000 correct (37.60%)\n",
      "\n",
      "Ireration: 670 loss: 1.7111868858337402\n",
      "Checking accuracy on the, val set\n",
      "Got 396 / 1000 correct (39.60%)\n",
      "\n",
      "Ireration: 680 loss: 1.647216558456421\n",
      "Checking accuracy on the, val set\n",
      "Got 402 / 1000 correct (40.20%)\n",
      "\n",
      "Ireration: 690 loss: 1.680465579032898\n",
      "Checking accuracy on the, val set\n",
      "Got 398 / 1000 correct (39.80%)\n",
      "\n",
      "Ireration: 700 loss: 1.9707002639770508\n",
      "Checking accuracy on the, val set\n",
      "Got 384 / 1000 correct (38.40%)\n",
      "\n",
      "Ireration: 710 loss: 1.5584971904754639\n",
      "Checking accuracy on the, val set\n",
      "Got 396 / 1000 correct (39.60%)\n",
      "\n",
      "Ireration: 720 loss: 1.822868824005127\n",
      "Checking accuracy on the, val set\n",
      "Got 411 / 1000 correct (41.10%)\n",
      "\n",
      "Ireration: 730 loss: 1.6128828525543213\n",
      "Checking accuracy on the, val set\n",
      "Got 412 / 1000 correct (41.20%)\n",
      "\n",
      "Ireration: 740 loss: 1.5968658924102783\n",
      "Checking accuracy on the, val set\n",
      "Got 391 / 1000 correct (39.10%)\n",
      "\n",
      "Ireration: 750 loss: 1.6077600717544556\n",
      "Checking accuracy on the, val set\n",
      "Got 422 / 1000 correct (42.20%)\n",
      "\n",
      "Ireration: 760 loss: 1.848251223564148\n",
      "Checking accuracy on the, val set\n",
      "Got 402 / 1000 correct (40.20%)\n",
      "\n",
      "Checking accuracy on the, test set\n",
      "Got 3868 / 10000 correct (38.68%)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "\n",
    "channel_1 = 16\n",
    "channel_2 = 32\n",
    "\n",
    "conv_w1 = random_weight((channel_1, 3, 5, 5))\n",
    "conv_b1 = random_weight((channel_1,))\n",
    "\n",
    "conv_w2 = random_weight((channel_2, channel_1, 7, 7))\n",
    "conv_b2 = random_weight((channel_2,))\n",
    "\n",
    "fc_w = random_weight((channel_2 * 32 * 32, 10))\n",
    "fc_b = random_weight((10,))\n",
    "\n",
    "\n",
    "params = (conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b)\n",
    "\n",
    "train_fn(three_layer_convnet, params, learning_rate)\n",
    "check_accuracy(loader_test, three_layer_convnet, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2f56632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_v2(loader, model):\n",
    "    split = \"val\" if loader.dataset.train else \"test\"\n",
    "    print(f\"Checking accuracy on the, {split} set\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    model.eval()  # set model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.int64)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print(\"Got %d / %d correct (%.2f%%)\" % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e4bf2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn_v2(model, optimizer, *, epochs=2, print_every=10):\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # putting model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.int64)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print(\"Iteration %d, loss = %.4f\" % (t, loss.item()))\n",
    "                check_accuracy_v2(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ac177",
   "metadata": {},
   "source": [
    "## Module API Pytorch Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb83a442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channel, channel_1, 5, padding=2)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        self.conv2 = nn.Conv2d(channel_1, channel_2, 7, padding=3)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        self.fc = nn.Linear(channel_2 * 32 * 32, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        scores = self.fc(flatten(x))\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "def test_ThreeLaterConvNet():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)\n",
    "    model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=32, num_classes=10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())\n",
    "\n",
    "\n",
    "test_ThreeLaterConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f874bdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.4130\n",
      "Checking accuracy on the, val set\n",
      "Got 105 / 1000 correct (10.50%)\n",
      "\n",
      "Iteration 10, loss = 2.2809\n",
      "Checking accuracy on the, val set\n",
      "Got 191 / 1000 correct (19.10%)\n",
      "\n",
      "Iteration 20, loss = 2.1173\n",
      "Checking accuracy on the, val set\n",
      "Got 151 / 1000 correct (15.10%)\n",
      "\n",
      "Iteration 30, loss = 2.1587\n",
      "Checking accuracy on the, val set\n",
      "Got 260 / 1000 correct (26.00%)\n",
      "\n",
      "Iteration 40, loss = 1.9512\n",
      "Checking accuracy on the, val set\n",
      "Got 240 / 1000 correct (24.00%)\n",
      "\n",
      "Iteration 50, loss = 2.0022\n",
      "Checking accuracy on the, val set\n",
      "Got 257 / 1000 correct (25.70%)\n",
      "\n",
      "Iteration 60, loss = 2.0800\n",
      "Checking accuracy on the, val set\n",
      "Got 277 / 1000 correct (27.70%)\n",
      "\n",
      "Iteration 70, loss = 2.0790\n",
      "Checking accuracy on the, val set\n",
      "Got 277 / 1000 correct (27.70%)\n",
      "\n",
      "Iteration 80, loss = 1.8662\n",
      "Checking accuracy on the, val set\n",
      "Got 256 / 1000 correct (25.60%)\n",
      "\n",
      "Iteration 90, loss = 2.0134\n",
      "Checking accuracy on the, val set\n",
      "Got 264 / 1000 correct (26.40%)\n",
      "\n",
      "Iteration 100, loss = 1.9267\n",
      "Checking accuracy on the, val set\n",
      "Got 333 / 1000 correct (33.30%)\n",
      "\n",
      "Iteration 110, loss = 1.8490\n",
      "Checking accuracy on the, val set\n",
      "Got 342 / 1000 correct (34.20%)\n",
      "\n",
      "Iteration 120, loss = 1.9459\n",
      "Checking accuracy on the, val set\n",
      "Got 328 / 1000 correct (32.80%)\n",
      "\n",
      "Iteration 130, loss = 2.1102\n",
      "Checking accuracy on the, val set\n",
      "Got 347 / 1000 correct (34.70%)\n",
      "\n",
      "Iteration 140, loss = 1.8712\n",
      "Checking accuracy on the, val set\n",
      "Got 322 / 1000 correct (32.20%)\n",
      "\n",
      "Iteration 150, loss = 1.8785\n",
      "Checking accuracy on the, val set\n",
      "Got 352 / 1000 correct (35.20%)\n",
      "\n",
      "Iteration 160, loss = 1.7558\n",
      "Checking accuracy on the, val set\n",
      "Got 355 / 1000 correct (35.50%)\n",
      "\n",
      "Iteration 170, loss = 1.9437\n",
      "Checking accuracy on the, val set\n",
      "Got 357 / 1000 correct (35.70%)\n",
      "\n",
      "Iteration 180, loss = 1.8243\n",
      "Checking accuracy on the, val set\n",
      "Got 327 / 1000 correct (32.70%)\n",
      "\n",
      "Iteration 190, loss = 1.7844\n",
      "Checking accuracy on the, val set\n",
      "Got 306 / 1000 correct (30.60%)\n",
      "\n",
      "Iteration 200, loss = 1.7762\n",
      "Checking accuracy on the, val set\n",
      "Got 356 / 1000 correct (35.60%)\n",
      "\n",
      "Iteration 210, loss = 1.9129\n",
      "Checking accuracy on the, val set\n",
      "Got 344 / 1000 correct (34.40%)\n",
      "\n",
      "Iteration 220, loss = 1.8251\n",
      "Checking accuracy on the, val set\n",
      "Got 358 / 1000 correct (35.80%)\n",
      "\n",
      "Iteration 230, loss = 1.9357\n",
      "Checking accuracy on the, val set\n",
      "Got 359 / 1000 correct (35.90%)\n",
      "\n",
      "Iteration 240, loss = 1.9474\n",
      "Checking accuracy on the, val set\n",
      "Got 373 / 1000 correct (37.30%)\n",
      "\n",
      "Iteration 250, loss = 1.9152\n",
      "Checking accuracy on the, val set\n",
      "Got 349 / 1000 correct (34.90%)\n",
      "\n",
      "Iteration 260, loss = 1.7801\n",
      "Checking accuracy on the, val set\n",
      "Got 369 / 1000 correct (36.90%)\n",
      "\n",
      "Iteration 270, loss = 1.8712\n",
      "Checking accuracy on the, val set\n",
      "Got 365 / 1000 correct (36.50%)\n",
      "\n",
      "Iteration 280, loss = 1.8491\n",
      "Checking accuracy on the, val set\n",
      "Got 377 / 1000 correct (37.70%)\n",
      "\n",
      "Iteration 290, loss = 1.8312\n",
      "Checking accuracy on the, val set\n",
      "Got 366 / 1000 correct (36.60%)\n",
      "\n",
      "Iteration 300, loss = 1.6915\n",
      "Checking accuracy on the, val set\n",
      "Got 355 / 1000 correct (35.50%)\n",
      "\n",
      "Iteration 310, loss = 1.7580\n",
      "Checking accuracy on the, val set\n",
      "Got 351 / 1000 correct (35.10%)\n",
      "\n",
      "Iteration 320, loss = 1.8473\n",
      "Checking accuracy on the, val set\n",
      "Got 377 / 1000 correct (37.70%)\n",
      "\n",
      "Iteration 330, loss = 1.9339\n",
      "Checking accuracy on the, val set\n",
      "Got 367 / 1000 correct (36.70%)\n",
      "\n",
      "Iteration 340, loss = 1.7250\n",
      "Checking accuracy on the, val set\n",
      "Got 366 / 1000 correct (36.60%)\n",
      "\n",
      "Iteration 350, loss = 1.7946\n",
      "Checking accuracy on the, val set\n",
      "Got 398 / 1000 correct (39.80%)\n",
      "\n",
      "Iteration 360, loss = 1.8737\n",
      "Checking accuracy on the, val set\n",
      "Got 422 / 1000 correct (42.20%)\n",
      "\n",
      "Iteration 370, loss = 1.7648\n",
      "Checking accuracy on the, val set\n",
      "Got 395 / 1000 correct (39.50%)\n",
      "\n",
      "Iteration 380, loss = 1.7339\n",
      "Checking accuracy on the, val set\n",
      "Got 354 / 1000 correct (35.40%)\n",
      "\n",
      "Iteration 390, loss = 1.6862\n",
      "Checking accuracy on the, val set\n",
      "Got 398 / 1000 correct (39.80%)\n",
      "\n",
      "Iteration 400, loss = 1.7331\n",
      "Checking accuracy on the, val set\n",
      "Got 394 / 1000 correct (39.40%)\n",
      "\n",
      "Iteration 410, loss = 1.7919\n",
      "Checking accuracy on the, val set\n",
      "Got 399 / 1000 correct (39.90%)\n",
      "\n",
      "Iteration 420, loss = 1.7647\n",
      "Checking accuracy on the, val set\n",
      "Got 386 / 1000 correct (38.60%)\n",
      "\n",
      "Iteration 430, loss = 1.6546\n",
      "Checking accuracy on the, val set\n",
      "Got 389 / 1000 correct (38.90%)\n",
      "\n",
      "Iteration 440, loss = 1.8226\n",
      "Checking accuracy on the, val set\n",
      "Got 374 / 1000 correct (37.40%)\n",
      "\n",
      "Iteration 450, loss = 1.6320\n",
      "Checking accuracy on the, val set\n",
      "Got 416 / 1000 correct (41.60%)\n",
      "\n",
      "Iteration 460, loss = 1.6968\n",
      "Checking accuracy on the, val set\n",
      "Got 405 / 1000 correct (40.50%)\n",
      "\n",
      "Iteration 470, loss = 1.6329\n",
      "Checking accuracy on the, val set\n",
      "Got 424 / 1000 correct (42.40%)\n",
      "\n",
      "Iteration 480, loss = 1.7609\n",
      "Checking accuracy on the, val set\n",
      "Got 422 / 1000 correct (42.20%)\n",
      "\n",
      "Iteration 490, loss = 1.8027\n",
      "Checking accuracy on the, val set\n",
      "Got 403 / 1000 correct (40.30%)\n",
      "\n",
      "Iteration 500, loss = 1.7399\n",
      "Checking accuracy on the, val set\n",
      "Got 422 / 1000 correct (42.20%)\n",
      "\n",
      "Iteration 510, loss = 1.7829\n",
      "Checking accuracy on the, val set\n",
      "Got 419 / 1000 correct (41.90%)\n",
      "\n",
      "Iteration 520, loss = 1.9113\n",
      "Checking accuracy on the, val set\n",
      "Got 409 / 1000 correct (40.90%)\n",
      "\n",
      "Iteration 530, loss = 1.6628\n",
      "Checking accuracy on the, val set\n",
      "Got 412 / 1000 correct (41.20%)\n",
      "\n",
      "Iteration 540, loss = 1.6826\n",
      "Checking accuracy on the, val set\n",
      "Got 402 / 1000 correct (40.20%)\n",
      "\n",
      "Iteration 550, loss = 1.6860\n",
      "Checking accuracy on the, val set\n",
      "Got 359 / 1000 correct (35.90%)\n",
      "\n",
      "Iteration 560, loss = 1.7656\n",
      "Checking accuracy on the, val set\n",
      "Got 389 / 1000 correct (38.90%)\n",
      "\n",
      "Iteration 570, loss = 1.8841\n",
      "Checking accuracy on the, val set\n",
      "Got 410 / 1000 correct (41.00%)\n",
      "\n",
      "Iteration 580, loss = 1.6471\n",
      "Checking accuracy on the, val set\n",
      "Got 430 / 1000 correct (43.00%)\n",
      "\n",
      "Iteration 590, loss = 1.5548\n",
      "Checking accuracy on the, val set\n",
      "Got 412 / 1000 correct (41.20%)\n",
      "\n",
      "Iteration 600, loss = 1.8224\n",
      "Checking accuracy on the, val set\n",
      "Got 370 / 1000 correct (37.00%)\n",
      "\n",
      "Iteration 610, loss = 1.6208\n",
      "Checking accuracy on the, val set\n",
      "Got 420 / 1000 correct (42.00%)\n",
      "\n",
      "Iteration 620, loss = 1.5727\n",
      "Checking accuracy on the, val set\n",
      "Got 421 / 1000 correct (42.10%)\n",
      "\n",
      "Iteration 630, loss = 1.6748\n",
      "Checking accuracy on the, val set\n",
      "Got 402 / 1000 correct (40.20%)\n",
      "\n",
      "Iteration 640, loss = 1.5224\n",
      "Checking accuracy on the, val set\n",
      "Got 419 / 1000 correct (41.90%)\n",
      "\n",
      "Iteration 650, loss = 1.6226\n",
      "Checking accuracy on the, val set\n",
      "Got 444 / 1000 correct (44.40%)\n",
      "\n",
      "Iteration 660, loss = 1.5683\n",
      "Checking accuracy on the, val set\n",
      "Got 411 / 1000 correct (41.10%)\n",
      "\n",
      "Iteration 670, loss = 1.5853\n",
      "Checking accuracy on the, val set\n",
      "Got 448 / 1000 correct (44.80%)\n",
      "\n",
      "Iteration 680, loss = 1.4734\n",
      "Checking accuracy on the, val set\n",
      "Got 406 / 1000 correct (40.60%)\n",
      "\n",
      "Iteration 690, loss = 1.6227\n",
      "Checking accuracy on the, val set\n",
      "Got 434 / 1000 correct (43.40%)\n",
      "\n",
      "Iteration 700, loss = 1.6214\n",
      "Checking accuracy on the, val set\n",
      "Got 417 / 1000 correct (41.70%)\n",
      "\n",
      "Iteration 710, loss = 1.4915\n",
      "Checking accuracy on the, val set\n",
      "Got 449 / 1000 correct (44.90%)\n",
      "\n",
      "Iteration 720, loss = 1.6484\n",
      "Checking accuracy on the, val set\n",
      "Got 451 / 1000 correct (45.10%)\n",
      "\n",
      "Iteration 730, loss = 1.7010\n",
      "Checking accuracy on the, val set\n",
      "Got 443 / 1000 correct (44.30%)\n",
      "\n",
      "Iteration 740, loss = 1.6290\n",
      "Checking accuracy on the, val set\n",
      "Got 444 / 1000 correct (44.40%)\n",
      "\n",
      "Iteration 750, loss = 1.6519\n",
      "Checking accuracy on the, val set\n",
      "Got 435 / 1000 correct (43.50%)\n",
      "\n",
      "Iteration 760, loss = 1.6626\n",
      "Checking accuracy on the, val set\n",
      "Got 428 / 1000 correct (42.80%)\n",
      "\n",
      "Iteration 0, loss = 1.6657\n",
      "Checking accuracy on the, val set\n",
      "Got 446 / 1000 correct (44.60%)\n",
      "\n",
      "Iteration 10, loss = 1.5357\n",
      "Checking accuracy on the, val set\n",
      "Got 457 / 1000 correct (45.70%)\n",
      "\n",
      "Iteration 20, loss = 1.5518\n",
      "Checking accuracy on the, val set\n",
      "Got 440 / 1000 correct (44.00%)\n",
      "\n",
      "Iteration 30, loss = 1.6766\n",
      "Checking accuracy on the, val set\n",
      "Got 444 / 1000 correct (44.40%)\n",
      "\n",
      "Iteration 40, loss = 1.7213\n",
      "Checking accuracy on the, val set\n",
      "Got 434 / 1000 correct (43.40%)\n",
      "\n",
      "Iteration 50, loss = 1.5796\n",
      "Checking accuracy on the, val set\n",
      "Got 462 / 1000 correct (46.20%)\n",
      "\n",
      "Iteration 60, loss = 1.6880\n",
      "Checking accuracy on the, val set\n",
      "Got 449 / 1000 correct (44.90%)\n",
      "\n",
      "Iteration 70, loss = 1.5244\n",
      "Checking accuracy on the, val set\n",
      "Got 459 / 1000 correct (45.90%)\n",
      "\n",
      "Iteration 80, loss = 1.8206\n",
      "Checking accuracy on the, val set\n",
      "Got 456 / 1000 correct (45.60%)\n",
      "\n",
      "Iteration 90, loss = 1.5815\n",
      "Checking accuracy on the, val set\n",
      "Got 453 / 1000 correct (45.30%)\n",
      "\n",
      "Iteration 100, loss = 1.7769\n",
      "Checking accuracy on the, val set\n",
      "Got 453 / 1000 correct (45.30%)\n",
      "\n",
      "Iteration 110, loss = 1.5853\n",
      "Checking accuracy on the, val set\n",
      "Got 437 / 1000 correct (43.70%)\n",
      "\n",
      "Iteration 120, loss = 1.6200\n",
      "Checking accuracy on the, val set\n",
      "Got 443 / 1000 correct (44.30%)\n",
      "\n",
      "Iteration 130, loss = 1.6781\n",
      "Checking accuracy on the, val set\n",
      "Got 432 / 1000 correct (43.20%)\n",
      "\n",
      "Iteration 140, loss = 1.5614\n",
      "Checking accuracy on the, val set\n",
      "Got 436 / 1000 correct (43.60%)\n",
      "\n",
      "Iteration 150, loss = 1.6664\n",
      "Checking accuracy on the, val set\n",
      "Got 392 / 1000 correct (39.20%)\n",
      "\n",
      "Iteration 160, loss = 1.5008\n",
      "Checking accuracy on the, val set\n",
      "Got 415 / 1000 correct (41.50%)\n",
      "\n",
      "Iteration 170, loss = 1.7410\n",
      "Checking accuracy on the, val set\n",
      "Got 473 / 1000 correct (47.30%)\n",
      "\n",
      "Iteration 180, loss = 1.4899\n",
      "Checking accuracy on the, val set\n",
      "Got 460 / 1000 correct (46.00%)\n",
      "\n",
      "Iteration 190, loss = 1.5747\n",
      "Checking accuracy on the, val set\n",
      "Got 436 / 1000 correct (43.60%)\n",
      "\n",
      "Iteration 200, loss = 1.6598\n",
      "Checking accuracy on the, val set\n",
      "Got 422 / 1000 correct (42.20%)\n",
      "\n",
      "Iteration 210, loss = 1.5679\n",
      "Checking accuracy on the, val set\n",
      "Got 467 / 1000 correct (46.70%)\n",
      "\n",
      "Iteration 220, loss = 1.3579\n",
      "Checking accuracy on the, val set\n",
      "Got 466 / 1000 correct (46.60%)\n",
      "\n",
      "Iteration 230, loss = 1.8442\n",
      "Checking accuracy on the, val set\n",
      "Got 466 / 1000 correct (46.60%)\n",
      "\n",
      "Iteration 240, loss = 1.5436\n",
      "Checking accuracy on the, val set\n",
      "Got 456 / 1000 correct (45.60%)\n",
      "\n",
      "Iteration 250, loss = 1.6144\n",
      "Checking accuracy on the, val set\n",
      "Got 446 / 1000 correct (44.60%)\n",
      "\n",
      "Iteration 260, loss = 1.6971\n",
      "Checking accuracy on the, val set\n",
      "Got 442 / 1000 correct (44.20%)\n",
      "\n",
      "Iteration 270, loss = 1.5647\n",
      "Checking accuracy on the, val set\n",
      "Got 423 / 1000 correct (42.30%)\n",
      "\n",
      "Iteration 280, loss = 1.5030\n",
      "Checking accuracy on the, val set\n",
      "Got 458 / 1000 correct (45.80%)\n",
      "\n",
      "Iteration 290, loss = 1.5822\n",
      "Checking accuracy on the, val set\n",
      "Got 467 / 1000 correct (46.70%)\n",
      "\n",
      "Iteration 300, loss = 1.6717\n",
      "Checking accuracy on the, val set\n",
      "Got 446 / 1000 correct (44.60%)\n",
      "\n",
      "Iteration 310, loss = 1.7425\n",
      "Checking accuracy on the, val set\n",
      "Got 457 / 1000 correct (45.70%)\n",
      "\n",
      "Iteration 320, loss = 1.5564\n",
      "Checking accuracy on the, val set\n",
      "Got 482 / 1000 correct (48.20%)\n",
      "\n",
      "Iteration 330, loss = 1.6114\n",
      "Checking accuracy on the, val set\n",
      "Got 457 / 1000 correct (45.70%)\n",
      "\n",
      "Iteration 340, loss = 1.5966\n",
      "Checking accuracy on the, val set\n",
      "Got 470 / 1000 correct (47.00%)\n",
      "\n",
      "Iteration 350, loss = 1.5873\n",
      "Checking accuracy on the, val set\n",
      "Got 470 / 1000 correct (47.00%)\n",
      "\n",
      "Iteration 360, loss = 1.5014\n",
      "Checking accuracy on the, val set\n",
      "Got 456 / 1000 correct (45.60%)\n",
      "\n",
      "Iteration 370, loss = 1.5768\n",
      "Checking accuracy on the, val set\n",
      "Got 459 / 1000 correct (45.90%)\n",
      "\n",
      "Iteration 380, loss = 1.5576\n",
      "Checking accuracy on the, val set\n",
      "Got 438 / 1000 correct (43.80%)\n",
      "\n",
      "Iteration 390, loss = 1.5776\n",
      "Checking accuracy on the, val set\n",
      "Got 465 / 1000 correct (46.50%)\n",
      "\n",
      "Iteration 400, loss = 1.9332\n",
      "Checking accuracy on the, val set\n",
      "Got 477 / 1000 correct (47.70%)\n",
      "\n",
      "Iteration 410, loss = 1.5555\n",
      "Checking accuracy on the, val set\n",
      "Got 431 / 1000 correct (43.10%)\n",
      "\n",
      "Iteration 420, loss = 1.6255\n",
      "Checking accuracy on the, val set\n",
      "Got 443 / 1000 correct (44.30%)\n",
      "\n",
      "Iteration 430, loss = 1.6498\n",
      "Checking accuracy on the, val set\n",
      "Got 462 / 1000 correct (46.20%)\n",
      "\n",
      "Iteration 440, loss = 1.4763\n",
      "Checking accuracy on the, val set\n",
      "Got 471 / 1000 correct (47.10%)\n",
      "\n",
      "Iteration 450, loss = 1.5352\n",
      "Checking accuracy on the, val set\n",
      "Got 459 / 1000 correct (45.90%)\n",
      "\n",
      "Iteration 460, loss = 1.5486\n",
      "Checking accuracy on the, val set\n",
      "Got 461 / 1000 correct (46.10%)\n",
      "\n",
      "Iteration 470, loss = 1.5943\n",
      "Checking accuracy on the, val set\n",
      "Got 492 / 1000 correct (49.20%)\n",
      "\n",
      "Iteration 480, loss = 1.5090\n",
      "Checking accuracy on the, val set\n",
      "Got 491 / 1000 correct (49.10%)\n",
      "\n",
      "Iteration 490, loss = 1.3575\n",
      "Checking accuracy on the, val set\n",
      "Got 487 / 1000 correct (48.70%)\n",
      "\n",
      "Iteration 500, loss = 1.6125\n",
      "Checking accuracy on the, val set\n",
      "Got 452 / 1000 correct (45.20%)\n",
      "\n",
      "Iteration 510, loss = 1.5460\n",
      "Checking accuracy on the, val set\n",
      "Got 475 / 1000 correct (47.50%)\n",
      "\n",
      "Iteration 520, loss = 1.6379\n",
      "Checking accuracy on the, val set\n",
      "Got 483 / 1000 correct (48.30%)\n",
      "\n",
      "Iteration 530, loss = 1.5313\n",
      "Checking accuracy on the, val set\n",
      "Got 479 / 1000 correct (47.90%)\n",
      "\n",
      "Iteration 540, loss = 1.4058\n",
      "Checking accuracy on the, val set\n",
      "Got 453 / 1000 correct (45.30%)\n",
      "\n",
      "Iteration 550, loss = 1.4240\n",
      "Checking accuracy on the, val set\n",
      "Got 481 / 1000 correct (48.10%)\n",
      "\n",
      "Iteration 560, loss = 1.4973\n",
      "Checking accuracy on the, val set\n",
      "Got 477 / 1000 correct (47.70%)\n",
      "\n",
      "Iteration 570, loss = 1.4058\n",
      "Checking accuracy on the, val set\n",
      "Got 483 / 1000 correct (48.30%)\n",
      "\n",
      "Iteration 580, loss = 1.6051\n",
      "Checking accuracy on the, val set\n",
      "Got 477 / 1000 correct (47.70%)\n",
      "\n",
      "Iteration 590, loss = 1.4826\n",
      "Checking accuracy on the, val set\n",
      "Got 489 / 1000 correct (48.90%)\n",
      "\n",
      "Iteration 600, loss = 1.5682\n",
      "Checking accuracy on the, val set\n",
      "Got 484 / 1000 correct (48.40%)\n",
      "\n",
      "Iteration 610, loss = 1.2769\n",
      "Checking accuracy on the, val set\n",
      "Got 479 / 1000 correct (47.90%)\n",
      "\n",
      "Iteration 620, loss = 1.3225\n",
      "Checking accuracy on the, val set\n",
      "Got 472 / 1000 correct (47.20%)\n",
      "\n",
      "Iteration 630, loss = 1.4723\n",
      "Checking accuracy on the, val set\n",
      "Got 468 / 1000 correct (46.80%)\n",
      "\n",
      "Iteration 640, loss = 1.3120\n",
      "Checking accuracy on the, val set\n",
      "Got 477 / 1000 correct (47.70%)\n",
      "\n",
      "Iteration 650, loss = 1.4275\n",
      "Checking accuracy on the, val set\n",
      "Got 482 / 1000 correct (48.20%)\n",
      "\n",
      "Iteration 660, loss = 1.6965\n",
      "Checking accuracy on the, val set\n",
      "Got 450 / 1000 correct (45.00%)\n",
      "\n",
      "Iteration 670, loss = 1.5357\n",
      "Checking accuracy on the, val set\n",
      "Got 457 / 1000 correct (45.70%)\n",
      "\n",
      "Iteration 680, loss = 1.5461\n",
      "Checking accuracy on the, val set\n",
      "Got 489 / 1000 correct (48.90%)\n",
      "\n",
      "Iteration 690, loss = 1.6460\n",
      "Checking accuracy on the, val set\n",
      "Got 478 / 1000 correct (47.80%)\n",
      "\n",
      "Iteration 700, loss = 1.6492\n",
      "Checking accuracy on the, val set\n",
      "Got 433 / 1000 correct (43.30%)\n",
      "\n",
      "Iteration 710, loss = 1.5256\n",
      "Checking accuracy on the, val set\n",
      "Got 497 / 1000 correct (49.70%)\n",
      "\n",
      "Iteration 720, loss = 1.3582\n",
      "Checking accuracy on the, val set\n",
      "Got 485 / 1000 correct (48.50%)\n",
      "\n",
      "Iteration 730, loss = 1.9044\n",
      "Checking accuracy on the, val set\n",
      "Got 446 / 1000 correct (44.60%)\n",
      "\n",
      "Iteration 740, loss = 1.5444\n",
      "Checking accuracy on the, val set\n",
      "Got 480 / 1000 correct (48.00%)\n",
      "\n",
      "Iteration 750, loss = 1.5174\n",
      "Checking accuracy on the, val set\n",
      "Got 471 / 1000 correct (47.10%)\n",
      "\n",
      "Iteration 760, loss = 1.6257\n",
      "Checking accuracy on the, val set\n",
      "Got 480 / 1000 correct (48.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1 = 16\n",
    "channel_2 = 32\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "model = ThreeLayerConvNet(3, channel_1, channel_2, 10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_fn_v2(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c2f6279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on the, test set\n",
      "Got 4756 / 10000 correct (47.56%)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy_v2(loader_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d46809",
   "metadata": {},
   "source": [
    "## Sequential API PyTorch Aproach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb9d8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a19d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.2995\n",
      "Checking accuracy on the, val set\n",
      "Got 108 / 1000 correct (10.80%)\n",
      "\n",
      "Iteration 10, loss = 2.2494\n",
      "Checking accuracy on the, val set\n",
      "Got 104 / 1000 correct (10.40%)\n",
      "\n",
      "Iteration 20, loss = 2.1408\n",
      "Checking accuracy on the, val set\n",
      "Got 242 / 1000 correct (24.20%)\n",
      "\n",
      "Iteration 30, loss = 2.1855\n",
      "Checking accuracy on the, val set\n",
      "Got 195 / 1000 correct (19.50%)\n",
      "\n",
      "Iteration 40, loss = 2.2497\n",
      "Checking accuracy on the, val set\n",
      "Got 175 / 1000 correct (17.50%)\n",
      "\n",
      "Iteration 50, loss = 2.1484\n",
      "Checking accuracy on the, val set\n",
      "Got 193 / 1000 correct (19.30%)\n",
      "\n",
      "Iteration 60, loss = 1.9519\n",
      "Checking accuracy on the, val set\n",
      "Got 290 / 1000 correct (29.00%)\n",
      "\n",
      "Iteration 70, loss = 1.9899\n",
      "Checking accuracy on the, val set\n",
      "Got 275 / 1000 correct (27.50%)\n",
      "\n",
      "Iteration 80, loss = 2.4651\n",
      "Checking accuracy on the, val set\n",
      "Got 192 / 1000 correct (19.20%)\n",
      "\n",
      "Iteration 90, loss = 2.1894\n",
      "Checking accuracy on the, val set\n",
      "Got 243 / 1000 correct (24.30%)\n",
      "\n",
      "Iteration 100, loss = 2.0831\n",
      "Checking accuracy on the, val set\n",
      "Got 243 / 1000 correct (24.30%)\n",
      "\n",
      "Iteration 110, loss = 2.0933\n",
      "Checking accuracy on the, val set\n",
      "Got 248 / 1000 correct (24.80%)\n",
      "\n",
      "Iteration 120, loss = 1.9637\n",
      "Checking accuracy on the, val set\n",
      "Got 296 / 1000 correct (29.60%)\n",
      "\n",
      "Iteration 130, loss = 1.7839\n",
      "Checking accuracy on the, val set\n",
      "Got 318 / 1000 correct (31.80%)\n",
      "\n",
      "Iteration 140, loss = 1.8700\n",
      "Checking accuracy on the, val set\n",
      "Got 339 / 1000 correct (33.90%)\n",
      "\n",
      "Iteration 150, loss = 2.0188\n",
      "Checking accuracy on the, val set\n",
      "Got 277 / 1000 correct (27.70%)\n",
      "\n",
      "Iteration 160, loss = 1.8047\n",
      "Checking accuracy on the, val set\n",
      "Got 314 / 1000 correct (31.40%)\n",
      "\n",
      "Iteration 170, loss = 1.9584\n",
      "Checking accuracy on the, val set\n",
      "Got 369 / 1000 correct (36.90%)\n",
      "\n",
      "Iteration 180, loss = 1.7836\n",
      "Checking accuracy on the, val set\n",
      "Got 333 / 1000 correct (33.30%)\n",
      "\n",
      "Iteration 190, loss = 1.5406\n",
      "Checking accuracy on the, val set\n",
      "Got 363 / 1000 correct (36.30%)\n",
      "\n",
      "Iteration 200, loss = 1.7795\n",
      "Checking accuracy on the, val set\n",
      "Got 376 / 1000 correct (37.60%)\n",
      "\n",
      "Iteration 210, loss = 1.9672\n",
      "Checking accuracy on the, val set\n",
      "Got 396 / 1000 correct (39.60%)\n",
      "\n",
      "Iteration 220, loss = 1.7705\n",
      "Checking accuracy on the, val set\n",
      "Got 366 / 1000 correct (36.60%)\n",
      "\n",
      "Iteration 230, loss = 1.8670\n",
      "Checking accuracy on the, val set\n",
      "Got 367 / 1000 correct (36.70%)\n",
      "\n",
      "Iteration 240, loss = 1.7262\n",
      "Checking accuracy on the, val set\n",
      "Got 377 / 1000 correct (37.70%)\n",
      "\n",
      "Iteration 250, loss = 1.7092\n",
      "Checking accuracy on the, val set\n",
      "Got 404 / 1000 correct (40.40%)\n",
      "\n",
      "Iteration 260, loss = 1.7189\n",
      "Checking accuracy on the, val set\n",
      "Got 427 / 1000 correct (42.70%)\n",
      "\n",
      "Iteration 270, loss = 1.7100\n",
      "Checking accuracy on the, val set\n",
      "Got 410 / 1000 correct (41.00%)\n",
      "\n",
      "Iteration 280, loss = 1.6384\n",
      "Checking accuracy on the, val set\n",
      "Got 401 / 1000 correct (40.10%)\n",
      "\n",
      "Iteration 290, loss = 1.9218\n",
      "Checking accuracy on the, val set\n",
      "Got 403 / 1000 correct (40.30%)\n",
      "\n",
      "Iteration 300, loss = 2.0580\n",
      "Checking accuracy on the, val set\n",
      "Got 383 / 1000 correct (38.30%)\n",
      "\n",
      "Iteration 310, loss = 1.7484\n",
      "Checking accuracy on the, val set\n",
      "Got 403 / 1000 correct (40.30%)\n",
      "\n",
      "Iteration 320, loss = 1.8122\n",
      "Checking accuracy on the, val set\n",
      "Got 437 / 1000 correct (43.70%)\n",
      "\n",
      "Iteration 330, loss = 1.5819\n",
      "Checking accuracy on the, val set\n",
      "Got 425 / 1000 correct (42.50%)\n",
      "\n",
      "Iteration 340, loss = 1.7135\n",
      "Checking accuracy on the, val set\n",
      "Got 409 / 1000 correct (40.90%)\n",
      "\n",
      "Iteration 350, loss = 1.7240\n",
      "Checking accuracy on the, val set\n",
      "Got 438 / 1000 correct (43.80%)\n",
      "\n",
      "Iteration 360, loss = 1.6182\n",
      "Checking accuracy on the, val set\n",
      "Got 438 / 1000 correct (43.80%)\n",
      "\n",
      "Iteration 370, loss = 1.6659\n",
      "Checking accuracy on the, val set\n",
      "Got 460 / 1000 correct (46.00%)\n",
      "\n",
      "Iteration 380, loss = 1.6497\n",
      "Checking accuracy on the, val set\n",
      "Got 418 / 1000 correct (41.80%)\n",
      "\n",
      "Iteration 390, loss = 1.6820\n",
      "Checking accuracy on the, val set\n",
      "Got 442 / 1000 correct (44.20%)\n",
      "\n",
      "Iteration 400, loss = 1.6256\n",
      "Checking accuracy on the, val set\n",
      "Got 450 / 1000 correct (45.00%)\n",
      "\n",
      "Iteration 410, loss = 1.5957\n",
      "Checking accuracy on the, val set\n",
      "Got 449 / 1000 correct (44.90%)\n",
      "\n",
      "Iteration 420, loss = 1.6129\n",
      "Checking accuracy on the, val set\n",
      "Got 429 / 1000 correct (42.90%)\n",
      "\n",
      "Iteration 430, loss = 1.4553\n",
      "Checking accuracy on the, val set\n",
      "Got 451 / 1000 correct (45.10%)\n",
      "\n",
      "Iteration 440, loss = 1.5664\n",
      "Checking accuracy on the, val set\n",
      "Got 446 / 1000 correct (44.60%)\n",
      "\n",
      "Iteration 450, loss = 1.6456\n",
      "Checking accuracy on the, val set\n",
      "Got 436 / 1000 correct (43.60%)\n",
      "\n",
      "Iteration 460, loss = 1.3399\n",
      "Checking accuracy on the, val set\n",
      "Got 448 / 1000 correct (44.80%)\n",
      "\n",
      "Iteration 470, loss = 1.6230\n",
      "Checking accuracy on the, val set\n",
      "Got 471 / 1000 correct (47.10%)\n",
      "\n",
      "Iteration 480, loss = 1.6135\n",
      "Checking accuracy on the, val set\n",
      "Got 442 / 1000 correct (44.20%)\n",
      "\n",
      "Iteration 490, loss = 1.6661\n",
      "Checking accuracy on the, val set\n",
      "Got 446 / 1000 correct (44.60%)\n",
      "\n",
      "Iteration 500, loss = 1.4658\n",
      "Checking accuracy on the, val set\n",
      "Got 461 / 1000 correct (46.10%)\n",
      "\n",
      "Iteration 510, loss = 1.5275\n",
      "Checking accuracy on the, val set\n",
      "Got 490 / 1000 correct (49.00%)\n",
      "\n",
      "Iteration 520, loss = 1.5810\n",
      "Checking accuracy on the, val set\n",
      "Got 465 / 1000 correct (46.50%)\n",
      "\n",
      "Iteration 530, loss = 1.4669\n",
      "Checking accuracy on the, val set\n",
      "Got 492 / 1000 correct (49.20%)\n",
      "\n",
      "Iteration 540, loss = 1.3098\n",
      "Checking accuracy on the, val set\n",
      "Got 473 / 1000 correct (47.30%)\n",
      "\n",
      "Iteration 550, loss = 1.2920\n",
      "Checking accuracy on the, val set\n",
      "Got 471 / 1000 correct (47.10%)\n",
      "\n",
      "Iteration 560, loss = 1.6425\n",
      "Checking accuracy on the, val set\n",
      "Got 479 / 1000 correct (47.90%)\n",
      "\n",
      "Iteration 570, loss = 1.6160\n",
      "Checking accuracy on the, val set\n",
      "Got 439 / 1000 correct (43.90%)\n",
      "\n",
      "Iteration 580, loss = 1.5056\n",
      "Checking accuracy on the, val set\n",
      "Got 482 / 1000 correct (48.20%)\n",
      "\n",
      "Iteration 590, loss = 1.3063\n",
      "Checking accuracy on the, val set\n",
      "Got 468 / 1000 correct (46.80%)\n",
      "\n",
      "Iteration 600, loss = 1.2443\n",
      "Checking accuracy on the, val set\n",
      "Got 515 / 1000 correct (51.50%)\n",
      "\n",
      "Iteration 610, loss = 1.6874\n",
      "Checking accuracy on the, val set\n",
      "Got 497 / 1000 correct (49.70%)\n",
      "\n",
      "Iteration 620, loss = 1.3551\n",
      "Checking accuracy on the, val set\n",
      "Got 483 / 1000 correct (48.30%)\n",
      "\n",
      "Iteration 630, loss = 1.5785\n",
      "Checking accuracy on the, val set\n",
      "Got 483 / 1000 correct (48.30%)\n",
      "\n",
      "Iteration 640, loss = 1.4850\n",
      "Checking accuracy on the, val set\n",
      "Got 499 / 1000 correct (49.90%)\n",
      "\n",
      "Iteration 650, loss = 1.5914\n",
      "Checking accuracy on the, val set\n",
      "Got 474 / 1000 correct (47.40%)\n",
      "\n",
      "Iteration 660, loss = 1.4919\n",
      "Checking accuracy on the, val set\n",
      "Got 485 / 1000 correct (48.50%)\n",
      "\n",
      "Iteration 670, loss = 1.5251\n",
      "Checking accuracy on the, val set\n",
      "Got 471 / 1000 correct (47.10%)\n",
      "\n",
      "Iteration 680, loss = 1.4916\n",
      "Checking accuracy on the, val set\n",
      "Got 511 / 1000 correct (51.10%)\n",
      "\n",
      "Iteration 690, loss = 1.4825\n",
      "Checking accuracy on the, val set\n",
      "Got 478 / 1000 correct (47.80%)\n",
      "\n",
      "Iteration 700, loss = 1.4435\n",
      "Checking accuracy on the, val set\n",
      "Got 489 / 1000 correct (48.90%)\n",
      "\n",
      "Iteration 710, loss = 1.3699\n",
      "Checking accuracy on the, val set\n",
      "Got 522 / 1000 correct (52.20%)\n",
      "\n",
      "Iteration 720, loss = 1.4848\n",
      "Checking accuracy on the, val set\n",
      "Got 500 / 1000 correct (50.00%)\n",
      "\n",
      "Iteration 730, loss = 1.4803\n",
      "Checking accuracy on the, val set\n",
      "Got 471 / 1000 correct (47.10%)\n",
      "\n",
      "Iteration 740, loss = 1.4088\n",
      "Checking accuracy on the, val set\n",
      "Got 488 / 1000 correct (48.80%)\n",
      "\n",
      "Iteration 750, loss = 1.5358\n",
      "Checking accuracy on the, val set\n",
      "Got 508 / 1000 correct (50.80%)\n",
      "\n",
      "Iteration 760, loss = 1.4339\n",
      "Checking accuracy on the, val set\n",
      "Got 500 / 1000 correct (50.00%)\n",
      "\n",
      "Iteration 0, loss = 1.5879\n",
      "Checking accuracy on the, val set\n",
      "Got 514 / 1000 correct (51.40%)\n",
      "\n",
      "Iteration 10, loss = 1.3866\n",
      "Checking accuracy on the, val set\n",
      "Got 492 / 1000 correct (49.20%)\n",
      "\n",
      "Iteration 20, loss = 1.1858\n",
      "Checking accuracy on the, val set\n",
      "Got 517 / 1000 correct (51.70%)\n",
      "\n",
      "Iteration 30, loss = 1.4232\n",
      "Checking accuracy on the, val set\n",
      "Got 492 / 1000 correct (49.20%)\n",
      "\n",
      "Iteration 40, loss = 1.2067\n",
      "Checking accuracy on the, val set\n",
      "Got 502 / 1000 correct (50.20%)\n",
      "\n",
      "Iteration 50, loss = 1.6766\n",
      "Checking accuracy on the, val set\n",
      "Got 518 / 1000 correct (51.80%)\n",
      "\n",
      "Iteration 60, loss = 1.3010\n",
      "Checking accuracy on the, val set\n",
      "Got 508 / 1000 correct (50.80%)\n",
      "\n",
      "Iteration 70, loss = 1.3526\n",
      "Checking accuracy on the, val set\n",
      "Got 515 / 1000 correct (51.50%)\n",
      "\n",
      "Iteration 80, loss = 1.4691\n",
      "Checking accuracy on the, val set\n",
      "Got 482 / 1000 correct (48.20%)\n",
      "\n",
      "Iteration 90, loss = 1.2928\n",
      "Checking accuracy on the, val set\n",
      "Got 523 / 1000 correct (52.30%)\n",
      "\n",
      "Iteration 100, loss = 1.4405\n",
      "Checking accuracy on the, val set\n",
      "Got 528 / 1000 correct (52.80%)\n",
      "\n",
      "Iteration 110, loss = 1.2934\n",
      "Checking accuracy on the, val set\n",
      "Got 511 / 1000 correct (51.10%)\n",
      "\n",
      "Iteration 120, loss = 1.5657\n",
      "Checking accuracy on the, val set\n",
      "Got 509 / 1000 correct (50.90%)\n",
      "\n",
      "Iteration 130, loss = 1.2259\n",
      "Checking accuracy on the, val set\n",
      "Got 520 / 1000 correct (52.00%)\n",
      "\n",
      "Iteration 140, loss = 1.4733\n",
      "Checking accuracy on the, val set\n",
      "Got 544 / 1000 correct (54.40%)\n",
      "\n",
      "Iteration 150, loss = 1.1376\n",
      "Checking accuracy on the, val set\n",
      "Got 512 / 1000 correct (51.20%)\n",
      "\n",
      "Iteration 160, loss = 1.4209\n",
      "Checking accuracy on the, val set\n",
      "Got 521 / 1000 correct (52.10%)\n",
      "\n",
      "Iteration 170, loss = 1.3109\n",
      "Checking accuracy on the, val set\n",
      "Got 529 / 1000 correct (52.90%)\n",
      "\n",
      "Iteration 180, loss = 1.3648\n",
      "Checking accuracy on the, val set\n",
      "Got 534 / 1000 correct (53.40%)\n",
      "\n",
      "Iteration 190, loss = 1.4183\n",
      "Checking accuracy on the, val set\n",
      "Got 511 / 1000 correct (51.10%)\n",
      "\n",
      "Iteration 200, loss = 1.3555\n",
      "Checking accuracy on the, val set\n",
      "Got 559 / 1000 correct (55.90%)\n",
      "\n",
      "Iteration 210, loss = 1.2199\n",
      "Checking accuracy on the, val set\n",
      "Got 519 / 1000 correct (51.90%)\n",
      "\n",
      "Iteration 220, loss = 1.2065\n",
      "Checking accuracy on the, val set\n",
      "Got 548 / 1000 correct (54.80%)\n",
      "\n",
      "Iteration 230, loss = 1.0412\n",
      "Checking accuracy on the, val set\n",
      "Got 537 / 1000 correct (53.70%)\n",
      "\n",
      "Iteration 240, loss = 1.1231\n",
      "Checking accuracy on the, val set\n",
      "Got 546 / 1000 correct (54.60%)\n",
      "\n",
      "Iteration 250, loss = 1.5904\n",
      "Checking accuracy on the, val set\n",
      "Got 536 / 1000 correct (53.60%)\n",
      "\n",
      "Iteration 260, loss = 1.5955\n",
      "Checking accuracy on the, val set\n",
      "Got 530 / 1000 correct (53.00%)\n",
      "\n",
      "Iteration 270, loss = 1.3901\n",
      "Checking accuracy on the, val set\n",
      "Got 559 / 1000 correct (55.90%)\n",
      "\n",
      "Iteration 280, loss = 1.3175\n",
      "Checking accuracy on the, val set\n",
      "Got 559 / 1000 correct (55.90%)\n",
      "\n",
      "Iteration 290, loss = 1.2930\n",
      "Checking accuracy on the, val set\n",
      "Got 549 / 1000 correct (54.90%)\n",
      "\n",
      "Iteration 300, loss = 1.3866\n",
      "Checking accuracy on the, val set\n",
      "Got 530 / 1000 correct (53.00%)\n",
      "\n",
      "Iteration 310, loss = 1.4424\n",
      "Checking accuracy on the, val set\n",
      "Got 537 / 1000 correct (53.70%)\n",
      "\n",
      "Iteration 320, loss = 1.5481\n",
      "Checking accuracy on the, val set\n",
      "Got 541 / 1000 correct (54.10%)\n",
      "\n",
      "Iteration 330, loss = 1.2005\n",
      "Checking accuracy on the, val set\n",
      "Got 548 / 1000 correct (54.80%)\n",
      "\n",
      "Iteration 340, loss = 1.1580\n",
      "Checking accuracy on the, val set\n",
      "Got 538 / 1000 correct (53.80%)\n",
      "\n",
      "Iteration 350, loss = 1.0745\n",
      "Checking accuracy on the, val set\n",
      "Got 547 / 1000 correct (54.70%)\n",
      "\n",
      "Iteration 360, loss = 1.4793\n",
      "Checking accuracy on the, val set\n",
      "Got 558 / 1000 correct (55.80%)\n",
      "\n",
      "Iteration 370, loss = 1.4624\n",
      "Checking accuracy on the, val set\n",
      "Got 543 / 1000 correct (54.30%)\n",
      "\n",
      "Iteration 380, loss = 1.5244\n",
      "Checking accuracy on the, val set\n",
      "Got 566 / 1000 correct (56.60%)\n",
      "\n",
      "Iteration 390, loss = 1.1134\n",
      "Checking accuracy on the, val set\n",
      "Got 537 / 1000 correct (53.70%)\n",
      "\n",
      "Iteration 400, loss = 1.4048\n",
      "Checking accuracy on the, val set\n",
      "Got 551 / 1000 correct (55.10%)\n",
      "\n",
      "Iteration 410, loss = 1.3293\n",
      "Checking accuracy on the, val set\n",
      "Got 549 / 1000 correct (54.90%)\n",
      "\n",
      "Iteration 420, loss = 1.2002\n",
      "Checking accuracy on the, val set\n",
      "Got 556 / 1000 correct (55.60%)\n",
      "\n",
      "Iteration 430, loss = 1.2239\n",
      "Checking accuracy on the, val set\n",
      "Got 520 / 1000 correct (52.00%)\n",
      "\n",
      "Iteration 440, loss = 1.0438\n",
      "Checking accuracy on the, val set\n",
      "Got 563 / 1000 correct (56.30%)\n",
      "\n",
      "Iteration 450, loss = 1.0666\n",
      "Checking accuracy on the, val set\n",
      "Got 566 / 1000 correct (56.60%)\n",
      "\n",
      "Iteration 460, loss = 1.2641\n",
      "Checking accuracy on the, val set\n",
      "Got 557 / 1000 correct (55.70%)\n",
      "\n",
      "Iteration 470, loss = 1.1970\n",
      "Checking accuracy on the, val set\n",
      "Got 576 / 1000 correct (57.60%)\n",
      "\n",
      "Iteration 480, loss = 1.2052\n",
      "Checking accuracy on the, val set\n",
      "Got 576 / 1000 correct (57.60%)\n",
      "\n",
      "Iteration 490, loss = 1.0782\n",
      "Checking accuracy on the, val set\n",
      "Got 558 / 1000 correct (55.80%)\n",
      "\n",
      "Iteration 500, loss = 1.0073\n",
      "Checking accuracy on the, val set\n",
      "Got 551 / 1000 correct (55.10%)\n",
      "\n",
      "Iteration 510, loss = 1.1156\n",
      "Checking accuracy on the, val set\n",
      "Got 559 / 1000 correct (55.90%)\n",
      "\n",
      "Iteration 520, loss = 1.1542\n",
      "Checking accuracy on the, val set\n",
      "Got 541 / 1000 correct (54.10%)\n",
      "\n",
      "Iteration 530, loss = 1.1626\n",
      "Checking accuracy on the, val set\n",
      "Got 571 / 1000 correct (57.10%)\n",
      "\n",
      "Iteration 540, loss = 1.0334\n",
      "Checking accuracy on the, val set\n",
      "Got 563 / 1000 correct (56.30%)\n",
      "\n",
      "Iteration 550, loss = 1.3013\n",
      "Checking accuracy on the, val set\n",
      "Got 562 / 1000 correct (56.20%)\n",
      "\n",
      "Iteration 560, loss = 1.1334\n",
      "Checking accuracy on the, val set\n",
      "Got 561 / 1000 correct (56.10%)\n",
      "\n",
      "Iteration 570, loss = 1.2944\n",
      "Checking accuracy on the, val set\n",
      "Got 579 / 1000 correct (57.90%)\n",
      "\n",
      "Iteration 580, loss = 1.3123\n",
      "Checking accuracy on the, val set\n",
      "Got 577 / 1000 correct (57.70%)\n",
      "\n",
      "Iteration 590, loss = 1.2452\n",
      "Checking accuracy on the, val set\n",
      "Got 562 / 1000 correct (56.20%)\n",
      "\n",
      "Iteration 600, loss = 1.3806\n",
      "Checking accuracy on the, val set\n",
      "Got 593 / 1000 correct (59.30%)\n",
      "\n",
      "Iteration 610, loss = 1.1735\n",
      "Checking accuracy on the, val set\n",
      "Got 593 / 1000 correct (59.30%)\n",
      "\n",
      "Iteration 620, loss = 1.2119\n",
      "Checking accuracy on the, val set\n",
      "Got 580 / 1000 correct (58.00%)\n",
      "\n",
      "Iteration 630, loss = 1.2869\n",
      "Checking accuracy on the, val set\n",
      "Got 595 / 1000 correct (59.50%)\n",
      "\n",
      "Iteration 640, loss = 0.9858\n",
      "Checking accuracy on the, val set\n",
      "Got 576 / 1000 correct (57.60%)\n",
      "\n",
      "Iteration 650, loss = 1.2373\n",
      "Checking accuracy on the, val set\n",
      "Got 584 / 1000 correct (58.40%)\n",
      "\n",
      "Iteration 660, loss = 1.3618\n",
      "Checking accuracy on the, val set\n",
      "Got 589 / 1000 correct (58.90%)\n",
      "\n",
      "Iteration 670, loss = 1.0029\n",
      "Checking accuracy on the, val set\n",
      "Got 584 / 1000 correct (58.40%)\n",
      "\n",
      "Iteration 680, loss = 1.2957\n",
      "Checking accuracy on the, val set\n",
      "Got 605 / 1000 correct (60.50%)\n",
      "\n",
      "Iteration 690, loss = 1.3147\n",
      "Checking accuracy on the, val set\n",
      "Got 599 / 1000 correct (59.90%)\n",
      "\n",
      "Iteration 700, loss = 1.2992\n",
      "Checking accuracy on the, val set\n",
      "Got 557 / 1000 correct (55.70%)\n",
      "\n",
      "Iteration 710, loss = 1.1955\n",
      "Checking accuracy on the, val set\n",
      "Got 575 / 1000 correct (57.50%)\n",
      "\n",
      "Iteration 720, loss = 1.1766\n",
      "Checking accuracy on the, val set\n",
      "Got 575 / 1000 correct (57.50%)\n",
      "\n",
      "Iteration 730, loss = 1.1235\n",
      "Checking accuracy on the, val set\n",
      "Got 574 / 1000 correct (57.40%)\n",
      "\n",
      "Iteration 740, loss = 1.0287\n",
      "Checking accuracy on the, val set\n",
      "Got 599 / 1000 correct (59.90%)\n",
      "\n",
      "Iteration 750, loss = 1.3479\n",
      "Checking accuracy on the, val set\n",
      "Got 581 / 1000 correct (58.10%)\n",
      "\n",
      "Iteration 760, loss = 1.3992\n",
      "Checking accuracy on the, val set\n",
      "Got 589 / 1000 correct (58.90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 16\n",
    "channel_2 = 32\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, channel_1, 5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_1, channel_2, 7, padding=3),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2 * 32 * 32, 10),\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "train_fn_v2(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0d40f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on the, test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 5817 / 10000 correct (58.17%)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy_v2(loader_test, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnncv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
